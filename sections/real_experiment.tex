\chapter{Real-world Experiment}
\label{ch:Real_Experiment} 

This chapter describes an experiment in a real-world setting. The purpose of this experiment is to test the hypothesis in natural conditions. In the following, we outline the steps for executing the
experiment and the results from the evaluation.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Data Extraction}
\label{sec:Real_Experiment:Extraction}

First, we extract the natural sentences from the MuST-SHE corpus, as presented in Subsection \ref{sec:Setup:Natural_Corpora}. We choose 10 sentences for the experiment, that contain no context information regarding the gender of the ambiguous words. The sentence set is balanced, containing 3 sentences of each two genders - male and female. All sentences are listed in Table \ref{tab:mustshe_sentences}.

\begin{table} 
    \begin{tabularx}{\linewidth}{|X|l|l|}
        \hline
        \textbf{Source Sentence} & \textbf{Ambiguous Word(s)} & \textbf{Gender} \\ \hline
        So now Thomson becomes the more likely \textbf{suspect}. & suspect & male \\ \hline
        There was one black \textbf{professor} and one black assistant \textbf{dean}. & professor, dean & male \\ \hline
        We have our cognitive biases, so that I can take a perfect history on a \textbf{patient} with chest pain. & patient & male \\ \hline
        That's the \textbf{officer} who emailed me back, saying I think you can have a few classes with us.  & officer & male \\ \hline
        Steve, a physician, told me about a \textbf{doctor} that he worked with who was never very respectful, especially to junior staff and nurses. & doctor & male \\ \hline
        What do you think a batting average for a \textbf{cardiac surgeon} or a \textbf{nurse practitioner} or an \textbf{orthopedic surgeon}, an \textbf{OBGYN}, a \textbf{paramedic} is supposed to be? & \makecell[tl]{surgeon, \\ nurse practitioner, \\ OBGYN, paramedic} & female \\ \hline
        Fortunately for Mama Jane and her \textbf{friend}, a \textbf{donor} had provided treatment so that we could take them to the nearest hospital three hours away. & friend, donor & female \\ \hline
        The three words are: Do you remember? "Do you remember that patient you sent home?" the other \textbf{nurse} asked matter-of-factly. "Well she's back," in just that tone of voice. & nurse & female \\ \hline
        This one comes from a note that a \textbf{student} sent me after I gave a lecture about arousal nonconcordance. & student & female \\ \hline
        At the end of a conference in a hotel lobby once, I'm literally on my way out the door and a \textbf{colleague} chases me down. "Emily, I just have a really quick question."  & colleague & female \\ \hline
    \end{tabularx}
    \caption{\textbf{Extracted Natural Sentences.} MuST-SHE 4th Category: No gender-disambiguating information can be retrieved. 10 sentences in total.}
    \label{tab:mustshe_sentences}
\end{table}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Data Preprocessing}
\label{sec:Real_Experiment:Preprocessing}

As next, we preprocess the data by unmasking for each word in each original sentence. For unmasking we use the BERT base model, introduced in Section \ref{sec:Experiments:Tools}. The model generates five most probable words for each masked word. We replace the unmasked words in the sentences with three of the generated words. For each original sentence, we have three times the number of words in the sentence unmasked sentences.

\paragraph{Sets of Sentences} We have the following multiple sets of sentences:
\begin{itemize}
    \item Original set: the extracted sentences, as shown in Table \ref{tab:mustshe_sentences}. 
    \item Unmasked word sets: $3*|words|$ unmasked sentences for each sentences ($|words|$ denotes the number of words in the sentence)
\end{itemize}

\paragraph{Manual Replacement} Since very often the ambiguous words in the original sentences are unmasked with ambiguous words as well, we try to mitigate this by manually replacing the gender ambiguous noun words with the following non-ambiguous words: \textit{man, woman, girl, guy, boy}. We compare this approach with the originally replaced words by the BERT model.


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Translation}
\label{sec:Real_Experiment:Translation}

We translate the sets of sentences from English to German in the two steps, also outlined in Section \ref{sec:Base_Experiment:Translation}:

\begin{enumerate}
    \item \textbf{Translation Source -> Target:} Translate the sets in the target language (German).
    \item \textbf{Backtranslation Target -> Source:} Translate the translations back into the source language (English).
\end{enumerate}

For translation, we use the Beam search decoding strategy (see Subsection \ref{sec:Background:Decoding}) with beam size 10. We choose this strategy based on the uniqueness evaluation results of the base experiment, where the number of unique sentences for the ambiguous subset is smaller than the number of unique sentences for the unambiguous subset, as expected.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Evaluation}
\label{sec:Real_Experiment:Evaluation}

For each original sentence, we execute the following algorithm:
\begin{enumerate}
    \item[1. ] Count the number of unique sentences in the backtranslations. \\
    $N \leftarrow |unique \; backtranslations|$ 
    \item[2. ] Count the number of unique sentences in the backtranslations for each unmasked word set of sentences. \\
    $w_{ij} \leftarrow |unique \; backtranslations \; for \; sentence \; with \; masked \; word \; w_{i} \; and \; mask \; j|$ \\
    $j \leftarrow \{1, 2, 3\}$ \\
    $i \leftarrow \{1, 2, ..., |words|\}$ \\
    $[w_{1j}, w_{2j}, ..., w_{|words|j}]$
    \item[3. ] Average the result for the three masks of each word. \\ 
    $w_{i}^{'} = \sum_{j=1}^{3} \frac{w_{ij}}{3} $ \\
    $[w_{1}^{'}, w_{2}^{'}, ..., w_{|words|}^{'}]$
    \item[4. ] Subtract the number of unique backtranslations of the original sentence from the average.
    $[|w_{1}^{'} - N|, |w_{2}^{'} - N|, ..., |w_{|words|}^{'} - N|]$ 
    \item[3.] Extract the words, which generate the 3 biggest differences. 
    
\end{enumerate}


Based on the Hypothesis \ref{a}, the original sentence containing an ambiguous word is expected to generate less unique sentences than the sentence with the corresponding unmasked ambiguous word, which is non-ambiguous. Therefore, this sentence is also expected to produce the biggest difference, when subtracting the number of unique sentences, pointing to the ambiguous word in the sentence. Since the natural sentences often exhibit more than one ambiguous word, we extract the three biggest differences, indicating three most ambiguous words in the original sentence.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Results}
\label{sec:Real_Experiment:Results}

The results from the evaluation can be seen in Table \ref{tab:mustshe_result}. We also compare the results of the replacement of the gender ambiguous nouns with BERT against the manual replacement. As we can see from the results, the manual replacement method achieves more detected ambiguous words in the list with the most probable ambiguous words. This proves that the theory of replacing ambiguous words with non-ambiguous words may help in detecting ambiguous words in a sentence. 


\begin{landscape}
    \begin{xltabular}{\linewidth}{|>{\hsize=1\hsize}X|>{\hsize=0.6\hsize}X|>{\hsize=0.7\hsize}X|>{\hsize=0.7\hsize}X|}
        \hline
        \textbf{Source Sentence} & \textbf{Ambiguous Word(s)} & \textbf{BERT Replacement} & \textbf{Manual Replacement} \\ \hline
        
        So now Thomson becomes the more likely \textbf{suspect}. & suspect & [now, the, Thomson, \textbf{suspect}, more] & [now, the, Thomson, \textbf{suspect}, more] \\ \hline
        
        There was one black \textbf{professor} and one black assistant \textbf{dean}. & professor, dean & [\textbf{professor}, There, and, . , was] &  [\textbf{dean}, There, and, . , was] \\ \hline
        
        We have our cognitive biases, so that I can take a perfect history on a \textbf{patient} with chest pain. & patient & [cognitive, chest, a, history, I] & [cognitive, chest, a, history, I] \\ \hline
        
        That's the \textbf{officer} who emailed me back, saying I think you can have a few classes with us.  & officer & [classes, saying, . , you, can] & [classes, saying, . , can, \textbf{officer}] \\ \hline
        
        Steve, a physician, told me about a \textbf{doctor} that he worked with who was never very respectful, especially to junior staff and nurses. & doctor & [nurses, respectful, Steve, staff, especially] & [nurses, \textbf{doctor}, respectful, Steve, staff] \\ \hline
        
        What do you think a batting average for a \textbf{cardiac surgeon} or a \textbf{nurse practitioner} or an \textbf{orthopedic surgeon}, an \textbf{OBGYN}, a \textbf{paramedic} is supposed to be? & surgeon, nurse practitioner, OBGYN, paramedic & [think, an, for, or, be] & [\textbf{paramedic}, think, an, for, or] \\ \hline
        
        Fortunately for Mama Jane and her \textbf{friend}, a \textbf{donor} had provided treatment so that we could take them to the nearest hospital three hours away. & friend, donor & [the, we, three, , , a] & [the, we, three, , , a] \\ \hline
        
        The three words are: Do you remember? "Do you remember that patient you sent home?" the other \textbf{nurse} asked matter-of-factly. "Well she's back," in just that tone of voice. & nurse & [you , you, are , words, \textbf{patient}] & [" , \textbf{nurse}, " , remember, of] \\ \hline
        
        This one comes from a note that a \textbf{student} sent me after I gave a lecture about arousal nonconcordance. & student & [one, comes, nonconcordance, arousal, note] & [one, comes, nonconcordance, arousal, \textbf{student}] \\ \hline
        
        At the end of a conference in a hotel lobby once, I'm literally on my way out the door and a \textbf{colleague} chases me down. "Emily, I just have a really quick question."  & colleague & [chases, way, have, end, down] & [chases, way, have, end, down] \\ \hline
        
        \caption{\textbf{Natural Experiment Results.} Displays the 3 most ambiguous words (sorted in descending order) for each sentence generated according to the evaluation. The marked words are the expected ambiguous words. \\ BERT Replacement: Unmasking of each word with the BERT model. \\ Manual Replacement: Unmasking of the gender ambiguous nouns manually with non-ambiguous nouns.}
        \label{tab:mustshe_result}
    \end{xltabular}  
\end{landscape} 

