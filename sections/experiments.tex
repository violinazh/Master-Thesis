\chapter{Experimental Framework}
\label{ch:Experiments}

% LANGUAGES: The source language I use for translation is English, because translating from a notional gender language (English) into a grammatical gender language (German, French, Bulgarian) can present a good example of existing biases by translating a non-gendered noun into the wrong gendered noun. Currently I am doing initial experiments on German, because it has available trained models and large datasets and I know the language, so I can manually inspect the results. Further into the project, the experiments will be extended to other language families and lower-resource languages such as Bulgarian.

% MODEL: Transformer model from fairseq
% - French-English WMT’14 model, finetuned on MuST-C data to use for MuST-SHE evaluation
% - German-English WMT’19

% DATASET: 
% - WMT: The sentences were selected from dozens of news websites and translated by professional translators.
% - MuST-C: recordings and transcription of TED talks
% - MuST-SHE: samples are balanced between masculine and feminine phenomena and contain sentences that present contextual information to disambiguate gender 
% - WinoMT: consists of 3,888 sentences presenting two human entities defined by their occupation and a subsequent pronoun that needs to be correctly resolved to one of the entities.



% Model: Transformer architecture
% Dataset: 
% -  Training on WMT, MuST-C
% - Challenge sets for gender: WinoMT (German), MuST-SHE (French)
% Source language: English 
% Target languages:
% - High resource: German (Germanic), French (Romance)
% - Low resource: Bulgarian (Slavic)

% Translation steps:
% 1) Translation English-German
% 2) Backtranslation German-English

% Beam search algorithm:
% - Beam size 10 
% - Beam size 100


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Corpora}
\label{sec:Experiments:Corpora}
- languages: three language families (Slavic, Germanic and Romance)
- datasets: test dataset for general MT model performance, test set (challenge set or natural corpora) for assessing gender bias


1) WinoMT challenge set
- concatenating Winogender and WinoBias; equally balanced between male and female genders as well as between stereotypical and non-stereotypical gender-role assignments (e.g., a female doctor versus a female nurse)
- uses data introduced by two recent coreference gender-bias studies: the
Winogender \parencite{Rudinger_2018_coreference}, and the WinoBias \cite{Zhao_2018_coreference} datasets
- Downsides: synthetic samples - controlled experiment environment, but may introduce some artificial biases; only English as source language; too small set for training easy to overfit

2) MuST-SHE corpus
- four different types of gender phenomena (interested in the 4th: No gender-disambiguating information can be retrieved)

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Models}
\label{sec:Experiments:Models}
- Transformer, fairseq

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Evaluation Methods}
\label{sec:Experiments:Evaluation}

Evaluation procedures ought to cover both models’ general performance and gender-related issues. This is crucial to establish the capabilities and limits of mitigating strategies \cite{Savoldi_2021}.

- Model performance metric: BLEU (translation quality)
- Gender accuracy metric (gender bias)

% \section{Technical Details}
% \label{sec:Experiments:Technical}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Hardware Resources}
\label{sec:Experiments:Hardware}
- GPU
- Batch size
- Training time

% \subsection{Hyperparameters}

Currently, I am focusing on doing some statistical evaluations on translations and backtranslations in German to attempt to detect patterns and prove the initial assumption, that ambiguous words generate less unique words in backtranslation than non-ambiguous words. 
I have extracted the first part of the sentences in WinoMT to obtain fully ambiguous sentences. And I disambiguated the sentence with both “male” and “female” to force the right translation in German.

1) Generate subset of WinoMT dataset for test
2) Statistics on test set:
- Gender produced in translation: for each source sentence how many of them produce both genders, male gender and female gender in translations
- Reoccurrence: how often ambiguous word reoccurs in backtranslation; for each source sentence how many of the sentences/ambiguous words reoccur in backtranslations
- Uniqueness: 
-- sentence level: out of the 100 backtranslated sentences to each source sentence how many are unique
-- word level: how many unique words in translation vs. backtranslation
- Word occurrence: Check number of unique words for each word in sentence: non-ambiguous words such as stop words like “the” should have less unique translations 
- Word alignment: out of 10 translations/backtranslations to each source sentence how many unique words to the ambiguous words are produced

