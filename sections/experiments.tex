\chapter{Experimental Framework}
\label{ch:Experiments}

% LANGUAGES: The source language I use for translation is English, because translating from a notional gender language (English) into a grammatical gender language (German, French, Bulgarian) can present a good example of existing biases by translating a non-gendered noun into the wrong gendered noun. Currently I am doing initial experiments on German, because it has available trained models and large datasets and I know the language, so I can manually inspect the results. Further into the project, the experiments will be extended to other language families and lower-resource languages such as Bulgarian.

% MODEL: Transformer model from fairseq
% - French-English WMT’14 model, finetuned on MuST-C data to use for MuST-SHE evaluation
% - German-English WMT’19

% DATASET: 
% - WMT: The sentences were selected from dozens of news websites and translated by professional translators.
% - MuST-C: recordings and transcription of TED talks
% - MuST-SHE: samples are balanced between masculine and feminine phenomena and contain sentences that present contextual information to disambiguate gender 
% - WinoMT: consists of 3,888 sentences presenting two human entities defined by their occupation and a subsequent pronoun that needs to be correctly resolved to one of the entities.



% Model: Transformer architecture
% Dataset: 
% -  Training on WMT, MuST-C
% - Challenge sets for gender: WinoMT (German), MuST-SHE (French)
% Source language: English 
% Target languages:
% - High resource: German (Germanic), French (Romance)
% - Low resource: Bulgarian (Slavic)

% Translation steps:
% 1) Translation English-German
% 2) Backtranslation German-English

% Beam search algorithm:
% - Beam size 10 
% - Beam size 100


\section{Corpora}
\label{sec:Experiments:Corpora}
- languages
- datasets: test dataset for general MT model performance, test set (challenge set or natural corpora) for assessing gender bias

\section{Models}
\label{sec:Experiments:Models}
- Transformer, fairseq

\section{Evaluation Methods}
\label{sec:Experiments:Evaluation}
- Model performance metric: BLEU (translation quality)
- Gender accuracy metric (gender bias)

% \section{Technical Details}
% \label{sec:Experiments:Technical}

\subsection{Hardware Resources}
\label{sec:Experiments:Hardware}
- GPU
- Batch size
- Training time

% \subsection{Hyperparameters}

Currently, I am focusing on doing some statistical evaluations on translations and backtranslations in German to attempt to detect patterns and prove the initial assumption, that ambiguous words generate less unique words in backtranslation than non-ambiguous words. 
I have extracted the first part of the sentences in WinoMT to obtain fully ambiguous sentences. And I disambiguated the sentence with both “male” and “female” to force the right translation in German.

1) Generate subset of WinoMT dataset for test
2) Statistics on test set:
- Gender produced in translation: for each source sentence how many of them produce both genders, male gender and female gender in translations
- Reoccurrence: how often ambiguous word reoccurs in backtranslation; for each source sentence how many of the sentences/ambiguous words reoccur in backtranslations
- Uniqueness: 
-- sentence level: out of the 100 backtranslated sentences to each source sentence how many are unique
-- word level: how many unique words in translation vs. backtranslation
- Word occurrence: Check number of unique words for each word in sentence: non-ambiguous words such as stop words like “the” should have less unique translations 
- Word alignment: out of 10 translations/backtranslations to each source sentence how many unique words to the ambiguous words are produced

